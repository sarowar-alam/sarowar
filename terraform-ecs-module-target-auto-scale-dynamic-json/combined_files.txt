modules\ecs-service\cloudwatch-cpu.tf
=====================================
# CPU-based Auto Scaling Policies
resource "aws_cloudwatch_metric_alarm" "cpu_high" {
  alarm_name          = "${var.ecs_service_name}-cpu-utilization-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "CPUUtilization"
  namespace           = "AWS/ECS"
  period              = 60
  statistic           = "Average"
  threshold           = 60
  alarm_description   = "Scale out when CPU utilization exceeds 60%"
  alarm_actions       = [aws_appautoscaling_policy.scale_out.arn]

  dimensions = {
    ClusterName = var.ecs_cluster_name
    ServiceName = aws_ecs_service.this.name
  }

  tags = merge(var.common_tags, {
    Name = "${var.ecs_service_name}-cpu-high"
  })
}

resource "aws_cloudwatch_metric_alarm" "cpu_low" {
  alarm_name          = "${var.ecs_service_name}-cpu-utilization-low"
  comparison_operator = "LessThanThreshold"
  evaluation_periods  = 5
  metric_name         = "CPUUtilization"
  namespace           = "AWS/ECS"
  period              = 60
  statistic           = "Average"
  threshold           = 30
  alarm_description   = "Scale in when CPU utilization is below 30%"
  alarm_actions       = [aws_appautoscaling_policy.scale_in.arn]

  dimensions = {
    ClusterName = var.ecs_cluster_name
    ServiceName = aws_ecs_service.this.name
  }

  tags = merge(var.common_tags, {
    Name = "${var.ecs_service_name}-cpu-low"
  })
}

# Step Scaling Policies for CPU
resource "aws_appautoscaling_policy" "scale_out" {
  name               = "${var.ecs_service_name}-cpu-scale-out"
  policy_type        = "StepScaling"
  resource_id        = aws_appautoscaling_target.this.resource_id
  scalable_dimension = aws_appautoscaling_target.this.scalable_dimension
  service_namespace  = aws_appautoscaling_target.this.service_namespace

  step_scaling_policy_configuration {
    adjustment_type         = "ChangeInCapacity"
    cooldown                = 60
    metric_aggregation_type = "Average"

    step_adjustment {
      metric_interval_lower_bound = 0
      metric_interval_upper_bound = 10
      scaling_adjustment          = 1
    }

    step_adjustment {
      metric_interval_lower_bound = 10
      metric_interval_upper_bound = 20
      scaling_adjustment          = 2
    }

    step_adjustment {
      metric_interval_lower_bound = 20
      scaling_adjustment          = 3
    }
  }
}

resource "aws_appautoscaling_policy" "scale_in" {
  name               = "${var.ecs_service_name}-cpu-scale-in"
  policy_type        = "StepScaling"
  resource_id        = aws_appautoscaling_target.this.resource_id
  scalable_dimension = aws_appautoscaling_target.this.scalable_dimension
  service_namespace  = aws_appautoscaling_target.this.service_namespace

  step_scaling_policy_configuration {
    adjustment_type         = "ChangeInCapacity"
    cooldown                = 300
    metric_aggregation_type = "Average"

    step_adjustment {
      metric_interval_upper_bound = 0
      scaling_adjustment          = -1
    }
  }
}

# Additional CloudWatch Alarms for Monitoring
resource "aws_cloudwatch_metric_alarm" "memory_high" {
  alarm_name          = "${var.ecs_service_name}-memory-utilization-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "MemoryUtilization"
  namespace           = "AWS/ECS"
  period              = 60
  statistic           = "Average"
  threshold           = 80
  alarm_description   = "Alarm when memory utilization exceeds 80%"

  dimensions = {
    ClusterName = var.ecs_cluster_name
    ServiceName = aws_ecs_service.this.name
  }

  tags = merge(var.common_tags, {
    Name = "${var.ecs_service_name}-memory-high"
  })
}



modules\ecs-service\main.tf
===========================
resource "aws_ecs_service" "this" {
  name            = var.ecs_service_name
  cluster         = var.ecs_cluster_id
  task_definition = aws_ecs_task_definition.this.arn

  desired_count                      = var.min_number_instances
  deployment_maximum_percent         = 200
  deployment_minimum_healthy_percent = 100
  health_check_grace_period_seconds  = var.health_check_grace_period

  load_balancer {
    target_group_arn = aws_lb_target_group.this.arn
    container_name   = var.ecs_service_name
    container_port   = var.container_port
  }

  network_configuration {
    security_groups  = [aws_security_group.ecs_service.id]
    subnets          = var.subnet_ids
    assign_public_ip = false
  }

  platform_version = "LATEST"

  enable_execute_command = true
  scheduling_strategy    = "REPLICA"

  capacity_provider_strategy {
    base              = 0
    capacity_provider = "FARGATE_SPOT"
    weight            = 1
  }

  deployment_circuit_breaker {
    enable   = true
    rollback = true
  }

  deployment_controller {
    type = "ECS"
  }

  enable_ecs_managed_tags = true
  propagate_tags          = "SERVICE"

  tags = merge(var.common_tags, {
    Name = var.ecs_service_name
  })

  depends_on = [aws_lb_listener.https, aws_ecs_task_definition.this]
}

resource "aws_ecs_task_definition" "this" {
  family                   = var.ecs_service_name
  requires_compatibilities = ["FARGATE"]
  task_role_arn            = var.iam_task_role_arn
  execution_role_arn       = var.ecs_task_execution_role_arn
  network_mode             = "awsvpc"
  cpu                      = var.cpu_size
  memory                   = var.memory_size

  container_definitions = jsonencode([{
    name   = var.ecs_service_name
    image  = var.image_uri
    cpu    = var.cpu_size
    memory = var.memory_size
    portMappings = [{
      containerPort = var.container_port
      hostPort      = var.container_port
      protocol      = "tcp"
    }]
    environmentFiles = var.env_file != "" ? [{
      value = var.env_file
      type  = "s3"
    }] : []
    logConfiguration = {
      logDriver = "awslogs"
      options = {
        "awslogs-group"         = aws_cloudwatch_log_group.this.name
        "awslogs-region"        = var.region
        "awslogs-stream-prefix" = "ecs"
      }
    }
    healthCheck = {
      command     = ["CMD-SHELL", "curl -f http://localhost:${var.container_port}${var.health_check_path} || exit 1"]
      interval    = 30
      timeout     = 5
      retries     = 3
      startPeriod = 60
    }
  }])

  runtime_platform {
    operating_system_family = "LINUX"
    cpu_architecture        = "X86_64"
  }

  ephemeral_storage {
    size_in_gib = var.ephemeral_size
  }

  tags = merge(var.common_tags, {
    Name = var.ecs_service_name
  })
}

# Load Balancer Resources
resource "aws_lb" "this" {
  name               = "${var.ecs_service_name}-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = var.public_subnet_ids

  enable_deletion_protection = false

  tags = merge(var.common_tags, {
    Name = "${var.ecs_service_name}-alb"
  })
}

resource "aws_lb_target_group" "this" {
  name        = "${var.ecs_service_name}-tg"
  port        = var.container_port
  protocol    = "HTTP"
  vpc_id      = var.vpc_id
  target_type = "ip"

  health_check {
    enabled             = true
    healthy_threshold   = 2
    unhealthy_threshold = 2
    timeout             = 5
    interval            = 30
    path                = var.health_check_path
    port                = "traffic-port"
    protocol            = "HTTP"
    matcher             = "200-299"
  }

  tags = merge(var.common_tags, {
    Name = "${var.ecs_service_name}-tg"
  })

  lifecycle {
    create_before_destroy = true
  }
}

resource "aws_lb_listener" "https" {
  load_balancer_arn = aws_lb.this.arn
  port              = 443
  protocol          = "HTTPS"
  ssl_policy        = "ELBSecurityPolicy-2016-08"
  certificate_arn   = var.acm_certificate_arn

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.this.arn
  }

  tags = merge(var.common_tags, {
    Name = "${var.ecs_service_name}-https"
  })
}

resource "aws_lb_listener" "http_redirect" {
  load_balancer_arn = aws_lb.this.arn
  port              = 80
  protocol          = "HTTP"

  default_action {
    type = "redirect"
    redirect {
      port        = "443"
      protocol    = "HTTPS"
      status_code = "HTTP_301"
    }
  }

  tags = merge(var.common_tags, {
    Name = "${var.ecs_service_name}-http-redirect"
  })
}

# Security Groups
resource "aws_security_group" "alb" {
  name        = "${var.ecs_service_name}-alb-sg"
  description = "Security group for ALB"
  vpc_id      = var.vpc_id

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = merge(var.common_tags, {
    Name = "${var.ecs_service_name}-alb-sg"
  })
}

resource "aws_security_group" "ecs_service" {
  name        = "${var.ecs_service_name}-ecs-sg"
  description = "Security group for ECS service"
  vpc_id      = var.vpc_id

  ingress {
    from_port       = var.container_port
    to_port         = var.container_port
    protocol        = "tcp"
    security_groups = [aws_security_group.alb.id]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = merge(var.common_tags, {
    Name = "${var.ecs_service_name}-ecs-sg"
  })
}

resource "aws_cloudwatch_log_group" "this" {
  name              = "/ecs/${var.ecs_service_name}"
  retention_in_days = 30

  tags = merge(var.common_tags, {
    Name = "/ecs/${var.ecs_service_name}"
  })
}

resource "aws_appautoscaling_target" "this" {
  max_capacity       = var.max_number_instances
  min_capacity       = var.min_number_instances
  resource_id        = "service/${var.ecs_cluster_name}/${aws_ecs_service.this.name}"
  scalable_dimension = "ecs:service:DesiredCount"
  service_namespace  = "ecs"

  depends_on = [aws_ecs_service.this]
}



modules\ecs-service\outputs.tf
==============================
output "ecs_service_name" {
  description = "ECS service name"
  value       = aws_ecs_service.this.name
}

output "ecs_service_arn" {
  description = "ECS service ARN"
  value       = aws_ecs_service.this.id
}

output "ecs_task_definition_arn" {
  description = "ECS task definition ARN"
  value       = aws_ecs_task_definition.this.arn
}

output "cloudwatch_log_group_name" {
  description = "CloudWatch log group name"
  value       = aws_cloudwatch_log_group.this.name
}

output "scale_out_policy_arn" {
  description = "Scale out policy ARN"
  value       = aws_appautoscaling_policy.scale_out.arn
}

output "scale_in_policy_arn" {
  description = "Scale in policy ARN"
  value       = aws_appautoscaling_policy.scale_in.arn
}


modules\ecs-service\variables.tf
================================
variable "ecs_service_name" {
  type        = string
  description = "Name of the ECS service"
}

variable "ecs_cluster_name" {
  type        = string
  description = "Name of the ECS cluster"
}

variable "ecs_cluster_id" {
  type        = string
  description = "ID of the ECS cluster"
}

variable "cpu_size" {
  type        = string
  description = "CPU units for the ECS task"
}

variable "memory_size" {
  type        = string
  description = "Memory for the ECS task"
}

variable "ephemeral_size" {
  type        = number
  description = "Ephemeral storage size in GiB"
}

variable "image_uri" {
  type        = string
  description = "ECR image URI for the container"
}

variable "env_file" {
  type        = string
  description = "S3 URI for environment file"
}

variable "sg_name" {
  type        = string
  description = "Security group ID for ECS service"
}

variable "subnet_names" {
  type        = string
  description = "Comma-separated list of subnet IDs"
}

variable "iam_task_role_arn" {
  type        = string
  description = "IAM task role ARN"
}

variable "max_number_instances" {
  type        = number
  description = "Maximum number of ECS tasks"
}

variable "min_number_instances" {
  type        = number
  description = "Minimum number of ECS tasks"
}

variable "threshold_num_messages" {
  type        = number
  description = "SQS queue depth threshold for scaling"
}

variable "sqs_name" {
  type        = string
  description = "SQS queue name"
}

variable "region" {
  type        = string
  description = "AWS region"
  default     = "us-west-2"
}

variable "common_tags" {
  type        = map(string)
  description = "Common tags for all resources"
  default     = {}
}
variable "container_port" {
  type        = number
  description = "Container port to expose"
  default     = 80
}

variable "health_check_path" {
  type        = string
  description = "Health check path for the application"
  default     = "/"
}

variable "health_check_grace_period" {
  type        = number
  description = "Health check grace period in seconds"
  default     = 60
}

variable "vpc_id" {
  type        = string
  description = "VPC ID"
}

variable "public_subnet_ids" {
  type        = list(string)
  description = "List of public subnet IDs for ALB"
}

variable "subnet_ids" {
  type        = list(string)
  description = "List of private subnet IDs for ECS tasks"
}

variable "acm_certificate_arn" {
  type        = string
  description = "ACM certificate ARN for HTTPS"
}

variable "ecs_task_execution_role_arn" {
  type        = string
  description = "ECS task execution role ARN"
}



ecs-services.json
=================
{
    "services": [
        {
            "ecs_name": "web-app-01",
            "cpu": 512,
            "memory": 1024,
            "disk_size": 21,
            "min_instances": 2,
            "max_instances": 10,
            "container_port": 80,
            "health_check_path": "/health",
            "health_check_grace_period": 60,
            "env": "arn:aws:s3:::bucket-name-store-env/rc/web-app-01/web-app-01.env",
            "cluster": "your-environment-fargate-container-cluster",
            "environment": "rc",
            "docker_file_path": "."
        }
    ]
}


main.tf
=======
terraform {
  required_version = "~> 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.53.0"
    }
  }

  backend "s3" {
    bucket = "your-terraform-state-bucket-name"
    region = "us-west-2"
    # terraform init -backend-config=backend.hcl
  }
}

provider "aws" {
  region = var.region
  
  default_tags {
    tags = {
      Environment = var.tag_environment
      System      = var.tag_system
      Owner       = var.tag_owner
      CostApp     = var.cost_app
      CostUnit    = var.tag_company
      Client      = var.tag_company
      Terraform   = "true"
    }
  }
}

module "ecs_service" {
  source = "./modules/ecs-service"

  # ECS Service Configuration
  ecs_service_name    = var.ecs_service_name
  ecs_cluster_name    = var.ecs_cluster_name
  ecs_cluster_id      = var.ecs_cluster_id
  cpu_size            = var.cpu_size
  memory_size         = var.memory_size
  ephemeral_size      = var.ephemeral_size
  image_uri           = var.image_uri
  env_file            = var.env_file
  
  # Networking
  sg_name      = var.sg_name
  subnet_names = var.subnet_names
  
  # IAM
  iam_task_role_arn = var.iam_task_role_arn
  
  # Auto Scaling
  max_number_instances    = var.max_number_instances
  min_number_instances    = var.min_number_instances
  threshold_num_messages  = var.threshold_num_messages
  
  # SQS
  sqs_name = var.sqs_name
  
  # Common Tags
  common_tags = local.common_tags
}

locals {
  common_tags = {
    Environment = var.tag_environment
    System      = var.tag_system
    Owner       = var.tag_owner
    CostApp     = var.cost_app
    CostUnit    = var.tag_company
    Client      = var.tag_company
  }
}


outputs.tf
==========
output "ecs_service_name" {
  description = "ECS service name"
  value       = module.ecs_service.ecs_service_name
}

output "ecs_service_arn" {
  description = "ECS service ARN"
  value       = module.ecs_service.ecs_service_arn
}

output "ecs_task_definition_arn" {
  description = "ECS task definition ARN"
  value       = module.ecs_service.ecs_task_definition_arn
}

output "cloudwatch_log_group_name" {
  description = "CloudWatch log group name"
  value       = module.ecs_service.cloudwatch_log_group_name
}

output "scale_out_policy_arn" {
  description = "Scale out policy ARN"
  value       = module.ecs_service.scale_out_policy_arn
}

output "scale_in_policy_arn" {
  description = "Scale in policy ARN"
  value       = module.ecs_service.scale_in_policy_arn
}


variables.tf
============
# Application Configuration
variable "ecs_service_name" {
  type        = string
  description = "Name of the ECS service"
}

variable "ecs_cluster_name" {
  type        = string
  description = "Name of the ECS cluster"
}

variable "ecs_cluster_id" {
  type        = string
  description = "ID of the ECS cluster"
}

# Resource Sizing
variable "cpu_size" {
  type        = string
  description = "CPU units for the ECS task"
}

variable "memory_size" {
  type        = string
  description = "Memory for the ECS task"
}

variable "ephemeral_size" {
  type        = number
  description = "Ephemeral storage size in GiB"
  default     = 21
}

# Container Configuration
variable "image_uri" {
  type        = string
  description = "ECR image URI for the container"
}

variable "env_file" {
  type        = string
  description = "S3 URI for environment file"
}

# Networking
variable "sg_name" {
  type        = string
  description = "Security group ID for ECS service"
}

variable "subnet_names" {
  type        = string
  description = "Comma-separated list of subnet IDs"
}

# IAM
variable "iam_task_role_arn" {
  type        = string
  description = "IAM task role ARN"
}

# Auto Scaling
variable "max_number_instances" {
  type        = number
  description = "Maximum number of ECS tasks"
  default     = 5
}

variable "min_number_instances" {
  type        = number
  description = "Minimum number of ECS tasks"
  default     = 1
}

variable "threshold_num_messages" {
  type        = number
  description = "SQS queue depth threshold for scaling"
}

# SQS
variable "sqs_name" {
  type        = string
  description = "SQS queue name"
}

# Environment & Region
variable "region" {
  type        = string
  description = "AWS region"
  default     = "us-west-2"
}

# Tags
variable "tag_environment" {
  type        = string
  description = "Environment tag (dev, staging, prod)"
}

variable "tag_system" {
  type        = string
  description = "System tag"
}

variable "tag_owner" {
  type        = string
  description = "Owner tag"
}

variable "tag_company" {
  type        = string
  description = "Company tag"
}

variable "cost_app" {
  type        = string
  description = "Cost application tag"
}

variable "container_port" {
  type        = number
  description = "Container port to expose"
  default     = 80
}

variable "health_check_path" {
  type        = string
  description = "Health check path for the application"
  default     = "/"
}

variable "vpc_id" {
  type        = string
  description = "VPC ID"
}

variable "public_subnet_ids" {
  type        = list(string)
  description = "List of public subnet IDs for ALB"
}

variable "private_subnet_ids" {
  type        = list(string)
  description = "List of private subnet IDs for ECS tasks"
}

variable "acm_certificate_arn" {
  type        = string
  description = "ACM certificate ARN for HTTPS"
}

variable "ecs_task_execution_role_arn" {
  type        = string
  description = "ECS task execution role ARN"
  default     = "arn:aws:iam::YOUR_ACCOUNT_ID:role/ecsTaskExecutionRole"
}



your-environment-rc-services.gvy
================================
import java.time.Instant
import org.jenkinsci.plugins.workflow.steps.FlowInterruptedException
import org.jenkinsci.plugins.workflow.steps.TimeoutStepExecution

def ECS_CHOICES = [
    'your-ecs-service-name-01',
    'your-ecs-service-name-02',
    'your-ecs-service-name-03',
    'your-ecs-service-name-N'  // Add more ECS service names as needed

]

pipeline {
    agent { label 'built-in' }

    parameters {
        choice(
            name: 'ECS_GLOBAL',
            choices: ECS_CHOICES,
            description: 'Select the ECS Name to Deploy'
        ) 
        string(
        defaultValue: 'RC', 
        description: 'Enter your Branch Name', 
        name: 'branch')      
    }

    environment {
        JSON_FILE_PATH = "terraform-ecs-module-auto-scale-dynamic-json/ecs-services.json"

        AWS_REGION="us-west-2"
        ECR_REPO="YOUR_ACCOUNT_ID.dkr.ecr.us-west-2.amazonaws.com"
        REPO_NAME = "${params.ECS_GLOBAL}"
        TAG="${params.ECS_GLOBAL}-${BUILD_NUMBER}"
        SOURCE_PATH="${WORKSPACE}/sourceCode" 

        TASK_ROLE_ARN="arn:aws:iam::YOUR_ACCOUNT_ID:role/Name_of_Your_Task_Role"
        TF_PATH="${WORKSPACE}/TerraFormCode/terraform-ecs-module-auto-scale-dynamic-json"

        SECURITY_GROUP_NAME= "Your_Security_Group_Name"
        SUBNET_NAME = "Your_Subnet_Name"

        TAG_COMPANY = "Your_Company_Name"
        TAG_OWNER = "Your_Owner_Name"
        TAG_SYSTEM = "YOur_System_Name"
        TAG_COSTAPP = "Your_Cost_Application"        
    }

    stages {
        stage('ECSConfiguration') {
            steps {
                script {
                    try {
                        echo "Reading JSON configuration from: ${JSON_FILE_PATH}"
                        if (!fileExists("${JSON_FILE_PATH}")) {
                            error "JSON configuration file not found at: ${JSON_FILE_PATH}"
                        }
                        def jsonText = readFile "${JSON_FILE_PATH}"
                        def jsonSlurper = new groovy.json.JsonSlurper()
                        def jsonFile = jsonSlurper.parseText(jsonText)
                        if (!jsonFile.services) {
                            error "JSON file does not contain 'services' array"
                        }
                        def selectedService = jsonFile.services.find { service ->
                            service.ecs_name == params.ECS_GLOBAL
                        }
                        
                        if (selectedService) {
                            echo "=== ECS Service Configuration for: ${params.ECS_GLOBAL} ==="
                            echo "CPU: ${selectedService.cpu}"
                            echo "Memory: ${selectedService.memory}"
                            echo "Disk Size: ${selectedService.disk_size}"
                            echo "Min Instances: ${selectedService.min_instances}"
                            echo "Max Instances: ${selectedService.max_instances}"
                            echo "Threshold: ${selectedService.threshold}"
                            echo "SQS: ${selectedService.sqs}"
                            echo "Environment: ${selectedService.env}"
                            echo "=================================================================="
                            env.SERVICE_NAME = selectedService.ecs_name.toString()
                            env.CLUSTER = selectedService.cluster.toString()
                            env.DEPLOY_ENV = selectedService.environment.toString()
                            env.ENV_FILE_NAME = selectedService.env.toString()
                            env.SELECTED_CPU = selectedService.cpu.toString()
                            env.SELECTED_MEMORY = selectedService.memory.toString()
                            env.SELECTED_DISK_SIZE = selectedService.disk_size.toString()
                            env.SELECTED_MIN_INSTANCES = selectedService.min_instances.toString()
                            env.SELECTED_MAX_INSTANCES = selectedService.max_instances.toString()
                            env.THRESHOLD_NUMBER_MESSAGE = selectedService.threshold.toString()
                            env.SERVICE_SQS_NAME = selectedService.sqs.toString()
                            env.SELECTED_DOCKER_FILE_PATH = selectedService.docker_file_path.toString()

                            
                        } else {
                            error "ECS service '${params.ECS_GLOBAL}' not found in JSON configuration at ${JSON_FILE_PATH}"
                        }
                        
                    } catch (FileNotFoundException e) {
                        error "JSON configuration file not found: ${e.message}"
                    } catch (Exception e) {
                        error "Failed to read ECS configuration: ${e.message}"
                    }
                }
            }
        }
    
        stage('ECS_Summary') {
            steps {
                script {
                    echo "=== Deployment Summary ==="
                    echo "Service: ${params.ECS_GLOBAL}"
                    echo "File: ${JSON_FILE_PATH}"
                    echo "CPU: ${env.SELECTED_CPU}"
                    echo "Memory: ${env.SELECTED_MEMORY}"
                    echo "Disk Size: ${env.SELECTED_DISK_SIZE}"
                    echo "Instance Range: ${env.SELECTED_MIN_INSTANCES} - ${env.SELECTED_MAX_INSTANCES}"
                    echo "Ready for deployment"
                }
            }
        }

        stage('ContainerBuild') {
            steps {
                dir('sourceCode') {
                    script{

                        def selectedOption = params.ECS_GLOBAL
                        echo selectedOption
                        try {
                            git(url: 'git@github.com:your_company_git/your_git_repo_name.git', branch: "${params.branch}", credentialsId: 'jenkins-git-access-key-id')
                            echo "Git Pulled from ${params.branch}, Service Name: ${params.ECS_GLOBAL}, Docker file path: ${env.SELECTED_DOCKER_FILE_PATH} Image: ${ECR_REPO}/${REPO_NAME}:${TAG}"
                            sh """
                            pwd
                            ls -lrth
                            """
                        } catch (Exception e) {
                            echo "Error occurred: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("TerraformInit stage failed: ${e.getMessage()}")
                        }
                        echo "ECS Service Name: ${params.ECS_GLOBAL}, Building the Image as: ${ECR_REPO}/${REPO_NAME}:${TAG}"
                        sh """
                            cd ${SOURCE_PATH} || { echo "Failed to change directory to ${SOURCE_PATH}"; exit 1; }
                            echo "Building Docker image from: ${env.SELECTED_DOCKER_FILE_PATH}"
                            # Build the image
                            
                            if [[ "${env.SELECTED_DOCKER_FILE_PATH}" == *"Dockerfile"* ]]; then

                                echo "Building Image with ${env.SELECTED_DOCKER_FILE_PATH}"
                                if ! docker build -f ${env.SELECTED_DOCKER_FILE_PATH} -t ${env.ECS_GLOBAL}:latest -t ${ECR_REPO}/${REPO_NAME}:${TAG} .; then
                                echo "Docker build failed"
                                exit 1
                                fi
                            else
                                cd "${env.SELECTED_DOCKER_FILE_PATH}" || { echo "Failed to change directory to ${env.SELECTED_DOCKER_FILE_PATH}"; exit 1; }
                                echo "Building Image with Dockerfile"
                                if ! docker build -f Dockerfile -t ${env.ECS_GLOBAL}:latest -t ${ECR_REPO}/${REPO_NAME}:${TAG} .; then
                                echo "Docker build failed"
                                exit 1
                                fi                                
                            fi

                            echo "Docker images created:"
                            docker images | grep -E "(${env.ECS_GLOBAL}|${REPO_NAME})"
                        """                        

                    } 
                }
            }
        }    

        stage('TrivySecurityScan') {
            steps {
                dir('sourceCode') {
                    script {
                        echo "Starting Trivy security scan for image: ${ECR_REPO}/${REPO_NAME}:${TAG}"
                        
                        try {
                            // Run Trivy scan and capture output
                            def trivyOutput = sh(
                                script: """
                                    set +e  # Continue on error to capture output even if vulnerabilities found
                                    trivy image --format table --exit-code 0 --severity CRITICAL,HIGH,MEDIUM ${ECR_REPO}/${REPO_NAME}:${TAG}
                                """,
                                returnStdout: true
                            ).trim()
                            
                            echo "=== TRIVY SCAN RESULTS ==="
                            echo trivyOutput
                            echo "=== END TRIVY SCAN RESULTS ==="
                            
                            // Count vulnerabilities by severity
                            def criticalCount = trivyOutput.count('CRITICAL')
                            def highCount = trivyOutput.count('HIGH')
                            def mediumCount = trivyOutput.count('MEDIUM')
                            
                            // Print summary
                            echo """
                            ===== TRIVY VULNERABILITY SUMMARY =====
                            CRITICAL Vulnerabilities: ${criticalCount}
                            HIGH Vulnerabilities: ${highCount}
                            MEDIUM Vulnerabilities: ${mediumCount}
                            =======================================
                            """
                            
                            // Quality gates - handle vulnerabilities based on severity
                            if (criticalCount > 0) {
                                error("Critical vulnerabilities detected in the image. Build failed.")
                            } else if (highCount > 0) {
                                error("High vulnerabilities detected in the image. Build failed.")
                            } else if (mediumCount > 0) {
                                error("Medium vulnerabilities detected in the image. Build failed.")
                            } else {
                                echo "No CRITICAL vulnerabilities detected."
                            }
                        } catch (Exception e) {
                            echo "Trivy scan failed: ${e.getMessage()}"
                            currentBuild.result = 'UNSTABLE'
                            // Don't fail the entire build, just mark as unstable
                        }
                    }
                }
            }
        }        

        stage('ECR_Login') {
            steps {
                script {
                    withCredentials([[
                        $class: 'UsernamePasswordMultiBinding', 
                        credentialsId: 'your-aws-iam-user-credentials-id',
                        usernameVariable: 'ACCESSKEY', 
                        passwordVariable: 'SECRETKEY'
                    ]]) {
                        try {
                            sh """
                                # Set AWS credentials
                                export AWS_ACCESS_KEY_ID=${ACCESSKEY}
                                export AWS_SECRET_ACCESS_KEY=${SECRETKEY}
                                export AWS_DEFAULT_REGION=${AWS_REGION}
                                
                                # Verify AWS credentials work
                                if ! /usr/local/bin/aws sts get-caller-identity; then
                                    echo "AWS credentials are invalid"
                                    exit 1
                                fi
                                
                                # Check if ECR repository exists, create if it doesn't
                                if ! /usr/local/bin/aws ecr describe-repositories --repository-names ${REPO_NAME} >/dev/null 2>&1; then
                                    echo "Creating ECR repository: ${REPO_NAME}"
                                    if ! /usr/local/bin/aws ecr create-repository \\
                                        --repository-name ${REPO_NAME} \\
                                        --image-tag-mutability MUTABLE \\
                                        --image-scanning-configuration scanOnPush=true \\
                                        --encryption-configuration encryptionType=AES256; then
                                        echo "Failed to create ECR repository"
                                        exit 1
                                    fi
                                    echo "ECR repository created successfully"
                                else
                                    echo "ECR repository ${REPO_NAME} already exists"
                                    
                                    # Update repository settings with error handling
                                    if ! /usr/local/bin/aws ecr put-image-tag-mutability \\
                                        --repository-name ${REPO_NAME} \\
                                        --image-tag-mutability MUTABLE; then
                                        echo "Warning: Failed to update image tag mutability"
                                    fi
                                    
                                    if ! /usr/local/bin/aws ecr put-image-scanning-configuration \\
                                        --repository-name ${REPO_NAME} \\
                                        --image-scanning-configuration scanOnPush=true; then
                                        echo "Warning: Failed to update image scanning configuration"
                                    fi
                                    
                                    echo "Repository settings updated"
                                fi
                                
                                # Login to ECR
                                if ! /usr/local/bin/aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_REPO; then
                                    echo "ECR login failed"
                                    exit 1
                                fi
                                
                                echo "Successfully logged in to ECR"
                            """
                        } catch (Exception e) {
                            echo "ECR login stage failed: ${e.getMessage()}"
                            error("ECR login failed")
                        }
                    }
                }
            }     
        }     

        stage('ECRPush') {
            steps {
                script {
                    try {
                        // Define ImageURI before use
                        def ImageURI = "${ECR_REPO}/${REPO_NAME}:${TAG}"
                        echo "Pushing Docker Image: ${ImageURI}"
                        sh """
                            docker push ${ImageURI}
                        """
                        echo "Docker Image Address: ${ImageURI}"
                        
                        // SET THE ENVIRONMENT VARIABLE HERE - after successful push
                        env.SuccessImageURI = ImageURI
                        echo "Stored image URI in environment variable: ${env.SuccessImageURI}"
                        
                        // Cleanup local image
                        def imageID = sh(script: "docker images -q ${ImageURI}", returnStdout: true).trim()
                        if (imageID) {
                            echo "Docker Image ID: ${imageID}"
                            def removeImageCommand = "docker rmi -f ${imageID} || echo 'Image not found or already removed'"
                            def result = sh(script: removeImageCommand, returnStatus: true)
                            if (result == 0) { 
                                echo "Image removed successfully" 
                            } else {
                                echo "Failed to remove image (exit code: ${result})"
                            }
                        } else { 
                            echo "Image not found locally" 
                        }
                        
                    } catch (Exception e) {
                        echo "Error occurred during ECR Push: ${e.getMessage()}"
                        
                        // Attempt cleanup even on failure
                        try {
                            def ImageURI = "${ECR_REPO}/${REPO_NAME}:${TAG}"
                            def imageID = sh(script: "docker images -q ${ImageURI}", returnStdout: true).trim()
                            if (imageID) {
                                sh "docker rmi -f ${imageID} || true"
                                echo "Cleaned up image after failed push"
                            }
                        } catch (Exception cleanupError) {
                            echo "Warning: Failed to cleanup image after push failure: ${cleanupError.getMessage()}"
                        }
                        
                        error("ECR Push failed")
                    }
                }
            }
        }

        stage('TerraformInit') {
            steps {
                dir('TerraFormCode') {
                    script {
                        try {
                            git (url: 'git@github.com:your_company_git/your_terraform_repo_name.git', branch: "main", credentialsId: 'your-jenkins-git-access-key-id')
                            sh """
                            pwd
                            ls -lrth ${TF_PATH}
                            """
                        } catch (Exception e) {
                            echo "Error occurred: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("TerraformInit stage failed: ${e.getMessage()}")
                        }
                    } 
                }
            }
        }


        stage('Create_tfvars_File') {
            steps {
                script {
                    dir("${TF_PATH}") {
                        def tfvarsContent = """
                        build = "${BUILD_NUMBER}"
                        image_uri = "${env.SuccessImageURI}"

                        ecs_service_name = "${env.SERVICE_NAME}"
                        region = "${AWS_REGION}"

                        env_file = "${env.ENV_FILE_NAME}"
                        cpu_size = ${env.SELECTED_CPU}
                        memory_size = ${env.SELECTED_MEMORY}
                        iam_task_role_arn = "${TASK_ROLE_ARN}"
                        ecs_cluster_name = "${env.CLUSTER}"
                        ephemeral_size = ${env.SELECTED_DISK_SIZE}
                        ecs_cluster_id = "arn:aws:ecs:us-west-2:YOUR_AWS_ACCOUNT_ID:cluster/${env.CLUSTER}"
                        min_number_Instances = ${env.SELECTED_MIN_INSTANCES}
                        max_number_Instances = ${env.SELECTED_MAX_INSTANCES}
                        threshold_num_messages = ${env.THRESHOLD_NUMBER_MESSAGE}
                        sqs_name = "${env.SERVICE_SQS_NAME}"
                        tag_company = "${TAG_COMPANY}"
                        tag_owner = "${TAG_OWNER}"
                        tag_system = "${TAG_SYSTEM}"
                        tag_environment = "${env.DEPLOY_ENV}"
                        cost_app = "${TAG_COSTAPP}"
                        sg_name = "${SECURITY_GROUP_NAME}"
                        subnet_names = "${SUBNET_NAME}"
                        """.stripIndent()
                        
                        writeFile(file: "${TF_PATH}/jenkinsvariables.tfvars", text: tfvarsContent)
                        sh "pwd && ls -l ${TF_PATH}/jenkinsvariables.tfvars && cat ${TF_PATH}/jenkinsvariables.tfvars"
                    }
                }
            }
        }


        stage('ECS_Deploy'){
            steps{
                script{
                    dir("${TF_PATH}"){
                        withCredentials([[$class: 'UsernamePasswordMultiBinding', credentialsId: 'your-jenkins-credentials-id',usernameVariable: 'ACCESSKEY', passwordVariable: 'SECRETKEY']])
                        {
                            sh """
                            export AWS_ACCESS_KEY_ID=$ACCESSKEY
                            export AWS_SECRET_ACCESS_KEY=$SECRETKEY
                            export AWS_DEFAULT_REGION=$AWS_REGION
                            echo "Path is: ${TF_PATH}"
                            echo "Environment is: ${env.DEPLOY_ENV}"
                            echo "Image is ${env.SuccessImageURI}"
                            pwd
                            cd ${TF_PATH}
                            pwd
                            terraform init -backend-config="key=ecs/your-environment-name/rc/${env.SERVICE_NAME}.tfstate" -var-file="${TF_PATH}/jenkinsvariables.tfvars"
                            terraform plan  -var-file="${TF_PATH}/jenkinsvariables.tfvars"
                            """ 
                            def userInput = null
                            def startTime = Instant.now()
                            try {
                                timeout(time: 30, unit: 'SECONDS') 
                                {
                                    userInput = input(id: 'userInput', message: 'Click "Proceed" to continue or "Abort" to stop:',parameters: [choice(name: 'CHOICE', choices: ['yes', 'no'], description: 'Click "Proceed" to continue or "Abort" to stop:')])
                                }
                            } catch (FlowInterruptedException e) {
                                if ((Instant.now().minusSeconds(startTime.getEpochSecond()).getEpochSecond()) > 29) 
                                {
                                    echo "Timeout detected! Elapsed time: ${Instant.now().minusSeconds(startTime.getEpochSecond()).getEpochSecond()} seconds. Setting userInput to 'yes'."
                                    userInput = 'yes'
                                } else 
                                {
                                    echo "Error: Pipeline was interrupted but NOT due to a timeout. Elapsed time: ${Instant.now().minusSeconds(startTime.getEpochSecond()).getEpochSecond()} seconds."
                                    currentBuild.result = 'FAILURE'  // Mark the pipeline as failed
                                    error("Pipeline interrupted unexpectedly before timeout.")
                                }
                            }
                            echo "Final User Input: ${userInput}"
                        if (userInput=='yes') {
                            echo 'User clicked "Proceed", continuing...'
                            sh """
                            export AWS_ACCESS_KEY_ID=$ACCESSKEY
                            export AWS_SECRET_ACCESS_KEY=$SECRETKEY
                            export AWS_DEFAULT_REGION=$AWS_REGION
                            echo "Path is: ${TF_PATH}"
                            echo "Image is ${env.SuccessImageURI}"
                            cd ${TF_PATH}
                            terraform init -backend-config="key=ecs/your-environment-name/rc/${env.SERVICE_NAME}.tfstate" -var-file="${TF_PATH}/jenkinsvariables.tfvars"
                            terraform plan  -var-file="${TF_PATH}/jenkinsvariables.tfvars"
                            terraform apply -auto-approve -var-file="${TF_PATH}/jenkinsvariables.tfvars"
                            ls -lrth ${TF_PATH}/jenkinsvariables.tfvars
                            """                         }  
                        } // End of With Credentials                  
                    }
                }
                
            }
        }



    }
    
    post {
        always {
            script {
                try {
                    // Check if the workspace directory exists
                    if (fileExists(env.WORKSPACE)) {
                        echo "Cleaning up workspace: ${env.WORKSPACE}"

                        // First approach: Delete all files and directories in the workspace
                        deleteDir()

                        // Second approach: Use cleanWs for more advanced cleanup with patterns
                        cleanWs(cleanWhenNotBuilt: false,
                                deleteDirs: true,
                                disableDeferredWipeout: true,
                                notFailBuild: true,
                                patterns: [[pattern: '.gitignore', type: 'INCLUDE'],
                                        [pattern: '.propsfile', type: 'EXCLUDE']])
                    } else {
                        echo "Workspace directory does not exist or already cleaned."
                    }
                } catch (Exception e) {
                    // Log the error but do not fail the build
                    echo "Error during workspace cleanup: ${e.message}"
                }
            }
        }
    }
}



